{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo scrape dietary restriction lists\n",
    "# https://www.traderjoes.com/dietary-lists/vegan\n",
    "# https://www.traderjoes.com/dietary-lists/kosher\n",
    "# https://www.traderjoes.com/dietary-lists/gluten-free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of 1/10/2020 Trader Joes has articles numberd ~4600 to ~ 5270\n",
    "flyer_numbers = range(4600, 5270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for pulling and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_name(soup):\n",
    "    return soup.find(\"h1\", {'class': 'lead'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_price(soup):\n",
    "    return soup.find(\"strong\", text=re.compile(\"(\\$\\d+\\.\\d+|\\d+¢)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(soup):\n",
    "    timeline = soup.find(string=re.compile('INGREDIENTS.*'))\n",
    "    if timeline:\n",
    "        return timeline.find_parents('div', {'class': 'pad-timeline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_and_nutrition(timeline):\n",
    "    if len(timeline) > 0:\n",
    "        #contents = [get_base_content(c) for c in timeline[0].contents if c.string not in ['\\n', ' ']]\n",
    "        raw_strings = [get_base_content(c) for c in timeline[0].contents]\n",
    "        clean_strings = get_clean_content(raw_strings)\n",
    "        if len(contents) > 0:\n",
    "            ingredients_ix = (index_containing_substring(clean_strings, \"INGREDIENTS\") + 1)\n",
    "            ingredients = clean_strings[ingredients_ix]\n",
    "            nutrition_ix = (index_containing_substring(clean_strings, \"NUTRITION\") + 1)\n",
    "            nutrition = clean_strings[nutrition_ix]\n",
    "            return ingredients, nutrition\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_containing_substring(list_, substr):\n",
    "    for i, s in enumerate(list_):\n",
    "        if substr in s:\n",
    "              return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_content(contents):\n",
    "    string = None\n",
    "    if contents.string:\n",
    "        string = contents.string\n",
    "    else:\n",
    "        string = \" \".join([c.string for c in contents.contents if c.string is not None])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_content(raw_strings):\n",
    "    clean_strings = []\n",
    "    for string in raw_strings:\n",
    "        if string not in ['\\n', ' ', u''] and '\\n' not in string:\n",
    "            clean_strings.append(string.strip())\n",
    "        elif '\\n' in string and string != '\\n':\n",
    "            split = [s.strip() for s in string.split('\\n')]\n",
    "            clean_strings = clean_strings + split\n",
    "    clean_strings = [c for c in clean_strings if c not in ['', '\\n']]\n",
    "    return clean_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    \"\"\" Takes a url and returns a soup object for that url \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(number, soup=None):\n",
    "    \"\"\" Takes a Flyer number and returns slightly processed data from the page \"\"\"\n",
    "    url = \"https://www.traderjoes.com/fearless-flyer/article/{}\".format(number)\n",
    "    if not soup:\n",
    "        soup = make_soup(url)\n",
    "    \n",
    "    # Product name\n",
    "    name = get_raw_name(soup)\n",
    "    # Product price\n",
    "    price = get_raw_price(soup)\n",
    "    # Timeline\n",
    "    timeline = get_timeline(soup)\n",
    "    # Ingredients and Nutrition facts\n",
    "    ingredients, nutrition = get_ingredients_and_nutrition(timeline)\n",
    "    \n",
    "    return {\n",
    "        'id': number,\n",
    "        'url': url,\n",
    "        'name': name,\n",
    "        'price': price,\n",
    "        'ingredients': ingredients,\n",
    "        'nutrition': nutrition\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for extracting final values from the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_servings(servings_string):\n",
    "    \"\"\" Returns the string with nutrition information \"\"\"\n",
    "    if servings_string:\n",
    "        try:\n",
    "            servings = re.compile('[0-9]*\\.?[0-9]+').findall(servings_string)\n",
    "            if servings:\n",
    "                return servings[0]\n",
    "        except:\n",
    "            print servings_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(price):\n",
    "    \"\"\" Takes a price string retunrs a number with the price per package \"\"\"\n",
    "    price = re.compile('[0-9]*\\.?[0-9]+').findall(price)\n",
    "    if price:\n",
    "        return price[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(name):\n",
    "    \"\"\" Takes a soup Tag and returns a cleaned string of the product name \"\"\"\n",
    "    if not name:\n",
    "        return \"\"\n",
    "    \n",
    "    string = None\n",
    "    if name.string:\n",
    "        string = name.string\n",
    "    elif name.contents:\n",
    "        string = name.contents[0].string\n",
    "    else:\n",
    "        string = \"\"\n",
    "    return  string.replace('\\n', '').replace('\\r','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nf(nf, key):\n",
    "    \"\"\"\n",
    "    Takes a string with nutrition fact information\n",
    "    and returns a quantity for a given key\n",
    "    \n",
    "    TODO: include a case in the regex for values including \"X less than 1g\"\n",
    "    see: https://www.traderjoes.com/fearless-flyer/article/4688\n",
    "    \"\"\"\n",
    "    if nf:\n",
    "        result = [v for v in nf if key in v]\n",
    "        if result:\n",
    "            re_str = r'({} ([0-9]*[.,]?[0-9]+g|[0-9]*[.,]?[0-9]+mg|[0-9]*[.,]?[0-9]+\\w|[0-9]*[.,]?[0-9]+mcg\\d+% DV)|Includes [0-9]*[.,]?[0-9]+g {})'.format(key, key)\n",
    "            qregex = re.compile(re_str)\n",
    "            quantity = qregex.findall(result[0])\n",
    "            quantity = quantity[0][0] if quantity else None\n",
    "            if quantity:\n",
    "                regex = re.compile('[0-9]*[.,]?[0-9]+')\n",
    "                quantity = regex.findall(quantity)[0]\n",
    "            return quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nutrition = {\n",
    "    'servings_per_container': None,\n",
    "    'serving_size': None,\n",
    "    'calories': None,\n",
    "    'total_fat': None,\n",
    "    'saturated_fat': None,\n",
    "    'trans_fat': None,\n",
    "    'cholesterol': None,\n",
    "    'sodium': None,\n",
    "    'total_carbs': None,\n",
    "    'fiber': None,\n",
    "    'total_sugars': None,\n",
    "    'protein': None,\n",
    "    'vit_a': None,\n",
    "    'vit_c': None,\n",
    "    'iron': None,\n",
    "    'calcium': None,\n",
    "    'potassium': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nutrition(nutrition_string):\n",
    "    \"\"\" Takes string of nutrition information and returns a dict \"\"\"\n",
    "    if nutrition_string:\n",
    "        try:\n",
    "            servings = nutrition_string.split('|')\n",
    "            servings_container = servings[0].split(':')[1].strip() if \":\" in servings[0] else servings[0]\n",
    "            serving_size = servings[1] if len(servings) > 1 else 'Varies by region'\n",
    "            nf = servings[2].split(',') if len(servings) > 1 else None\n",
    "            return {\n",
    "                'servings_per_container': servings_container,\n",
    "                'serving_size': serving_size,\n",
    "                'calories': get_nf(nf, 'Calories'),\n",
    "                'total_fat': get_nf(nf, 'Total Fat'),\n",
    "                'saturated_fat': get_nf(nf, 'Saturated Fat'),\n",
    "                'trans_fat': get_nf(nf, 'Trans Fat'),\n",
    "                'cholesterol': get_nf(nf, 'Cholesterol'),\n",
    "                'sodium': get_nf(nf, 'Sodium'),\n",
    "                'total_carbs': get_nf(nf, 'Total Carbohydrate'),\n",
    "                'fiber': get_nf(nf, 'Dietary Fiber'),\n",
    "                'sugars': get_nf(nf, 'Sugars'),\n",
    "                'total_sugars': get_nf(nf, 'Total Sugars'),\n",
    "                'added_sugars': get_nf(nf, 'Added Sugars'),\n",
    "                'protein': get_nf(nf, 'Protein'),\n",
    "                'vit_a': get_nf(nf, 'Vitamin A'),\n",
    "                'vit_c': get_nf(nf, 'Vitamin C'),\n",
    "                'vit_d': get_nf(nf, 'Vitamin D'),\n",
    "                'iron': get_nf(nf, 'Iron'),\n",
    "                'calcium': get_nf(nf, 'Calcium'),\n",
    "                'potassium': get_nf(nf, 'Potassium')\n",
    "            }\n",
    "        except Exception, e:\n",
    "            return base_nutrition\n",
    "    else:\n",
    "        return base_nutrition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching, Processing, and Exporting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of urls of Flyer pages\n",
    "urls = [\"https://www.traderjoes.com/fearless-flyer/article/{}\".format(number) for number in flyer_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the html and create a list of soup objects for each page\n",
    "soups = [make_soup(url) for url in urls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data to extract the relevant chunks of htmls\n",
    "data = [make_data(number, soup) for number, soup in zip(flyer_numbers, soups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the preprocessed data into a dataframe\n",
    "ffdf = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the nutrition information in the preprocessed data\n",
    "nutrition_data = [d for d in ffdf.nutrition.apply(process_nutrition).tolist() if d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "nutrition_df = pd.DataFrame(nutrition_data)\n",
    "nutrition_df.serving_size.fillna('', inplace=True)\n",
    "nutrition_df.servings_per_container.fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the nutrition information back to the original dataframe\n",
    "df = pd.concat([ffdf, nutrition_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =[\n",
    "    'id', 'url', 'name', 'price', 'servings', \n",
    "    'serving_size', 'cost_per_serving', \n",
    "    'calories', 'protein', 'total_fat', \n",
    "    'total_carbs', 'sugars', 'total_sugars', 'added_sugars',\n",
    "    'sodium', 'fiber', 'iron', 'potassium',\n",
    "    'vit_a', 'vit_c', 'calcium', 'trans_fat' \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run some final processing on the data\n",
    "df['name'] = df.name.apply(get_name)\n",
    "df['price'] = df.price.apply(get_price).astype(float)\n",
    "df['servings'] = df.servings_per_container.apply(get_servings).astype(float)\n",
    "df['cost_per_serving'] = df.price / df.servings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df[df.name != \"\"][columns].to_csv('./clean_flyer_data2.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old Shit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [make_data(number, soup) for number, soup in zip(flyer_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffdf = pd.DataFrame(\n",
    "#     zipped_ff, \n",
    "#     columns=['id', 'url', 'name', 'price', 'timelines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the nutrition information\n",
    "# ffdf['nutrition'] = (ffdf\n",
    "#     .timelines\n",
    "#     .apply(lambda s: s.text.split('NUTRITION FACTS')[1].replace('\\n', '').strip() if s and len(s.text.split('NUTRITION FACTS')) > 1 else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver \n",
    "# from selenium.webdriver.common.by import By \n",
    "# from selenium.webdriver.support.ui import WebDriverWait \n",
    "# from selenium.webdriver.support import expected_conditions as EC \n",
    "# from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# option = webdriver.ChromeOptions()\n",
    "# option.add_argument(\" — incognito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# browser = webdriver.Chrome(executable_path='/Users/pdarche/Downloads/chromedriver 2', chrome_options=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_base_content(contents, found=set()):\n",
    "#     string = None\n",
    "#     if contents.string:\n",
    "#         found.add(contents.string)\n",
    "#     else:\n",
    "#         for content in contents.contents:\n",
    "#             get_base_content(content, found)\n",
    "#     return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haunted = ffdf[ffdf.id == 4985].nutrition.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# haunted_nf = haunted.split('|')[2].split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restr = r'({} ([0-9]*[.,]?[0-9]+g|[0-9]*[.,]?[0-9]+mg|[0-9]*[.,]?[0-9]+\\w|[0-9]*[.,]?[0-9]+mcg\\d+% DV)|Includes [0-9]*[.,]?[0-9]+g {})'.format('Total Sugars', 'Added Sugars')\n",
    "# print(restr)\n",
    "# qregex = re.compile(restr)\n",
    "# quantity = qregex.findall(haunted_nf[7])\n",
    "# print(quantity)\n",
    "# get_nf(haunted_nf, 'Total Fat')\n",
    "# haunted_nf\n",
    "# process_nutrition(haunted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
