{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import itertools\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As of 1/10/2020 Trader Joes has articles numberd ~4600 to ~ 5270\n",
    "flyer_numbers = range(4600, 5270)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions for pulling and pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_name(soup):\n",
    "    return soup.find(\"h1\", {'class': 'lead'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_price(soup):\n",
    "    return soup.find(\"strong\", text=re.compile(\"(\\$\\d+\\.\\d+|\\d+¢)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeline(soup):\n",
    "    timeline = soup.find(string=re.compile('INGREDIENTS.*'))\n",
    "    if timeline:\n",
    "        return timeline.find_parents('div', {'class': 'pad-timeline'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingredients_and_nutrition(timeline):\n",
    "    if timeline and len(timeline) > 0:\n",
    "        raw_strings = [get_base_content(c) for c in timeline[0].contents]\n",
    "        clean_strings = get_clean_content(raw_strings)\n",
    "        if len(clean_strings) > 0:\n",
    "            ingredients_ix = (index_containing_substring(clean_strings, \"INGREDIENTS\") + 1)\n",
    "            ingredients = clean_strings[ingredients_ix]\n",
    "            nutrition_ix = (index_containing_substring(clean_strings, \"NUTRITION\") + 1)\n",
    "            nutrition = clean_strings[nutrition_ix]\n",
    "            return ingredients, nutrition\n",
    "        else:\n",
    "            return None, None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_containing_substring(list_, substr):\n",
    "    for i, s in enumerate(list_):\n",
    "        if substr in s:\n",
    "              return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_content(contents):\n",
    "    string = None\n",
    "    if contents.string:\n",
    "        string = contents.string\n",
    "    else:\n",
    "        string = \" \".join([c.string for c in contents.contents if c.string is not None])\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_content(raw_strings):\n",
    "    clean_strings = []\n",
    "    for string in raw_strings:\n",
    "        if string not in ['\\n', ' ', u''] and '\\n' not in string:\n",
    "            clean_strings.append(string.strip())\n",
    "        elif '\\n' in string and string != '\\n':\n",
    "            split = [s.strip() for s in string.split('\\n')]\n",
    "            clean_strings = clean_strings + split\n",
    "    clean_strings = [c for c in clean_strings if c not in ['', '\\n']]\n",
    "    return clean_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    \"\"\" Takes a url and returns a soup object for that url \"\"\"\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tag_data(number, soup=None):\n",
    "    \"\"\" Takes a Flyer number and returns slightly processed data from the page \"\"\"\n",
    "    url = \"https://www.traderjoes.com/fearless-flyer/article/{}\".format(number)\n",
    "    if not soup:\n",
    "        soup = make_soup(url)\n",
    "    \n",
    "    # Product name\n",
    "    name = get_raw_name(soup)\n",
    "    # Product price\n",
    "    price = get_raw_price(soup)\n",
    "    # Timeline\n",
    "    timeline = get_timeline(soup)\n",
    "    \n",
    "    return (number, url, name, price, timeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for extracting string values from the tag data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_string_data(tag_data):\n",
    "    \"\"\" Takes a Flyer number and returns slightly processed data from the page \"\"\"\n",
    "    id, url, name_tag, price_tag, timeline_tag = tag_data\n",
    "    \n",
    "    # Product name\n",
    "    name = get_name_string(name_tag)\n",
    "    # Product price\n",
    "    price = get_price_string(price_tag)\n",
    "    # Ingredients and Nutrition facts\n",
    "    ingredients, nutrition = get_ingredients_and_nutrition(timeline_tag)\n",
    "    \n",
    "    return (id, url, name, price, ingredients, nutrition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_string(price):\n",
    "    \"\"\" Takes a price string retunrs a number with the price per package \"\"\"\n",
    "    if not price:\n",
    "        return \"\"\n",
    "    \n",
    "    price_string = \"\"\n",
    "    if type(price) == str:\n",
    "        price_string = price\n",
    "    elif price.string:\n",
    "        price_string = price.string\n",
    "    elif price.contents:\n",
    "        price_string = price.contents[0].string\n",
    "    else:\n",
    "        price_string = \"\"\n",
    "  \n",
    "    return price_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name_string(name):\n",
    "    \"\"\" Takes a soup Tag and returns a cleaned string of the product name \"\"\"\n",
    "    if not name:\n",
    "        return \"\"\n",
    "    \n",
    "    string = \"\"\n",
    "    if name.string:\n",
    "        string = name.string\n",
    "    elif name.contents:\n",
    "        string = name.contents[0].string\n",
    "    else:\n",
    "        string = \"\"\n",
    "    return  string.replace('\\n', '').replace('\\r','').strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for extracting the final structured data from the raw string data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price(price_string):\n",
    "    \"\"\"Extracts the price information from the \"\"\"\n",
    "    price = re.compile('[0-9]*\\.?[0-9]+').findall(price_string)\n",
    "    \n",
    "    if price:\n",
    "        if \"¢\" in price_string:\n",
    "            price = \".\" + price[0]\n",
    "        else:\n",
    "            price = price[0]\n",
    "        return float(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_servings(servings_string):\n",
    "    \"\"\" Returns the string with nutrition information \"\"\"\n",
    "    if not servings_string:\n",
    "        return None\n",
    "    \n",
    "    if servings_string:\n",
    "        try:\n",
    "            servings = re.compile('[0-9]*\\.?[0-9]+').findall(servings_string)\n",
    "            if servings:\n",
    "                return float(servings[0])\n",
    "        except:\n",
    "            print(servings_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nf(nf, key):\n",
    "    \"\"\"\n",
    "    Takes a string with nutrition fact information\n",
    "    and returns a quantity for a given key\n",
    "    \n",
    "    TODO: include a case in the regex for values including \"X less than 1g\"\n",
    "    see: https://www.traderjoes.com/fearless-flyer/article/4688\n",
    "    \"\"\"\n",
    "    if nf:\n",
    "        result = [v for v in nf if key in v]\n",
    "        if result:\n",
    "            re_str = r'({} ([0-9]*[.,]?[0-9]+g|[0-9]*[.,]?[0-9]+mg|[0-9]*[.,]?[0-9]+\\w|[0-9]*[.,]?[0-9]+mcg\\d+% DV)|Includes [0-9]*[.,]?[0-9]+g {})'.format(key, key)\n",
    "            qregex = re.compile(re_str)\n",
    "            quantity = qregex.findall(result[0])\n",
    "            quantity = quantity[0][0] if quantity else None\n",
    "            if quantity:\n",
    "                regex = re.compile('[0-9]*[.,]?[0-9]+')\n",
    "                quantity = regex.findall(quantity)[0]\n",
    "            else:\n",
    "                quantity = None\n",
    "            return quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nutrition = {\n",
    "    'servings_per_container': None,\n",
    "    'serving_size': None,\n",
    "    'calories': None,\n",
    "    'total_fat': None,\n",
    "    'saturated_fat': None,\n",
    "    'trans_fat': None,\n",
    "    'cholesterol': None,\n",
    "    'sodium': None,\n",
    "    'total_carbs': None,\n",
    "    'fiber': None,\n",
    "    'total_sugars': None,\n",
    "    'protein': None,\n",
    "    'vit_a': None,\n",
    "    'vit_c': None,\n",
    "    'iron': None,\n",
    "    'calcium': None,\n",
    "    'potassium': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nutrition(nutrition_string):\n",
    "    \"\"\" Takes string of nutrition information and returns a dict \"\"\"\n",
    "    if nutrition_string:\n",
    "        try:\n",
    "            servings = nutrition_string.split('|')\n",
    "            servings_container = servings[0].split(':')[1].strip() if \":\" in servings[0] else servings[0]\n",
    "            serving_size = servings[1].strip() if len(servings) > 1 else None\n",
    "            nf = servings[2].split(',') if len(servings) > 1 else None\n",
    "            return {\n",
    "                'servings_per_container': servings_container,\n",
    "                'serving_size': serving_size,\n",
    "                'calories': get_nf(nf, 'Calories'),\n",
    "                'total_fat': get_nf(nf, 'Total Fat'),\n",
    "                'saturated_fat': get_nf(nf, 'Saturated Fat'),\n",
    "                'trans_fat': get_nf(nf, 'Trans Fat'),\n",
    "                'cholesterol': get_nf(nf, 'Cholesterol'),\n",
    "                'sodium': get_nf(nf, 'Sodium'),\n",
    "                'total_carbs': get_nf(nf, 'Total Carbohydrate'),\n",
    "                'fiber': get_nf(nf, 'Dietary Fiber'),\n",
    "                'sugars': get_nf(nf, 'Sugars'),\n",
    "                'total_sugars': get_nf(nf, 'Total Sugars'),\n",
    "                'added_sugars': get_nf(nf, 'Added Sugars'),\n",
    "                'protein': get_nf(nf, 'Protein'),\n",
    "                'vit_a': get_nf(nf, 'Vitamin A'),\n",
    "                'vit_c': get_nf(nf, 'Vitamin C'),\n",
    "                'vit_d': get_nf(nf, 'Vitamin D'),\n",
    "                'iron': get_nf(nf, 'Iron'),\n",
    "                'calcium': get_nf(nf, 'Calcium'),\n",
    "                'potassium': get_nf(nf, 'Potassium')\n",
    "            }\n",
    "        except Exception:\n",
    "            return base_nutrition\n",
    "    else:\n",
    "        return base_nutrition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_final_data(string_data):\n",
    "    \"\"\"\n",
    "    Creates a dictionary of the final data for the food\n",
    "    \"\"\"\n",
    "    id, url, name_string, price_string, ingredients_string, nutrition_string = string_data\n",
    "    \n",
    "    # Get final price data\n",
    "    price = get_price(price_string)\n",
    "    \n",
    "    final_dict = {\n",
    "        'id': id,\n",
    "        'url': url,\n",
    "        'name': name_string,\n",
    "        'price': price\n",
    "    }\n",
    "    \n",
    "    nutrition_dict = process_nutrition(nutrition_string)\n",
    "    servings = get_servings(nutrition_dict.get('servings_per_container'))\n",
    "    \n",
    "    nutrition_dict['servings'] = servings if servings else None\n",
    "    nutrition_dict['cost_per_serving'] = price / servings if price and servings else None\n",
    "        \n",
    "    final_dict.update(nutrition_dict)\n",
    "    final_dict['vegan'] = 1 if find_similar(name_string, 'vegan') else 0\n",
    "    final_dict['gluten_free'] = 1 if find_similar(name_string, 'gluten-free') else 0\n",
    "    final_dict['kosher'] = 1 if find_similar(name_string, 'kosher') else 0\n",
    "    \n",
    "    return final_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching, Processing, and Exporting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of urls of Flyer pages\n",
    "# urls = [\"https://www.traderjoes.com/fearless-flyer/article/{}\".format(number) for number in flyer_numbers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the html and create a list of soup objects for each page\n",
    "# soups = [make_soup(url) for url in urls]\n",
    "# soups = pickle.load(open( \"../data/fearless_flyer_soups.pkl\", \"rb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle.dump(soups, open(\"../data/fearless_flyer_soups.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_data = [make_tag_data(number, soup) for number, soup in zip(flyer_numbers, soups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_data = [make_string_data(data) for data in tag_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = [make_final_data(data) for data in string_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns =[\n",
    "    'id', 'url', 'name', 'price', 'servings', \n",
    "    'serving_size', 'cost_per_serving', \n",
    "    'calories', 'protein', 'total_fat',\n",
    "    'trans_fat', 'saturated_fat', 'cholesterol',\n",
    "    'total_carbs', 'sugars', 'total_sugars', 'added_sugars',\n",
    "    'sodium', 'fiber', 'iron', 'potassium',\n",
    "    'vit_a', 'vit_c', 'calcium', 'trans_fat',\n",
    "    'vegan', 'gluten_free', 'kosher'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export\n",
    "df[df.name != \"\"][columns].to_csv('../data/clean_flyer_data3.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.name != \"\"][columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dietary Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dietary_list_foods(dietary_type):\n",
    "    html = requests.get(\"https://www.traderjoes.com/dietary-lists/{}\".format(dietary_type)).text\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    headers = soup.find_all('p', {'class': 'subheader4'})\n",
    "    tags = [tag.next_sibling.next_sibling for tag in headers]\n",
    "    contents = [get_base_content(tag) for tag in tags]\n",
    "    foods = get_clean_content(contents)\n",
    "    return foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "vegan_foods = get_dietary_list_foods('vegan')\n",
    "gf_foods = get_dietary_list_foods('gluten-free')\n",
    "k_foods = get_dietary_list_foods('kosher')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('../data/clean_fearless_flyer_with_interest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(list1, list2):\n",
    "    s1 = set(list1)\n",
    "    s2 = set(list2)\n",
    "    return len(s1.intersection(s2)) / len(s1.union(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dietary_restrictions = {\n",
    "    'vegan': vegan_foods,\n",
    "    'gluten-free': gf_foods,\n",
    "    'kosher': k_foods\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(name, key):\n",
    "    foods = dietary_restrictions.get(key)\n",
    "    foods_lists = [food.split() for food in foods]\n",
    "    scores = [jaccard_similarity(name.split(), food) for food in foods_lists]\n",
    "    max_index = np.argmax(scores)\n",
    "    max_score = scores[max_index]\n",
    "    match = foods[max_index] if max_score > .6 else None\n",
    "    return match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vegan'] = df.name.apply(lambda n: find_most_similar(n, 'vegan'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gluten_free'] = df.name.apply(lambda n: find_most_similar(n, 'gluten-free'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['kosher'] = df.name.apply(lambda n: find_most_similar(n, 'kosher'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/clean_fearless_flyer_with_interest_and_dietary_restrictions.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
